1. Запустить spark-shell, зайти в Application UI этого приложения.

```bash
# запуск из контейнера
docker compose up spark-master
docker compose up spark-worker

# заходим в bash контейнера
docker exec -it 1f0013c7d868 bash

# запускаем spark-shell
spark-shell --master spark://1f0013c7d868:7077
```

2. Прочитать данные в формате csv, задав строго схему данных в файле с помощью
   StructType(Array( StructField(...), ...   ))

```scala

val schemaShop = StructType(Array(
  StructField("event_time", DateType, true),
  StructField("event_type", StringType, true),
  StructField("product_id", IntegerType, true),
  StructField("category_id", LongType, true),
  StructField("category_code", StringType, true),
  StructField("brand", StringType, true),
  StructField("price", DoubleType, true),
  StructField("user_id", IntegerType, true),
  StructField("user_session", StringType, true),
  StructField("date", DateType, true)
)
)


spark.read.option("inferSchema", "true").option("header", "true").csv("/data/events_data_csv/2021-11-25").show()

val dfShopShema = spark.read.option("header", "true").schema(schemaShop).csv("/data/events_data_csv/2021-11-25")

scala > dfShopShema.printSchema
root
|-- event_time: date
(nullable = true)
|-- event_type: string
(nullable = true)
|-- product_id: integer
(nullable = true)
|-- category_id: long
(nullable = true)
|-- category_code: string
(nullable = true)
|-- brand: string
(nullable = true)
|-- price: double
(nullable = true)
|-- user_id: integer
(nullable = true)
|-- user_session: string
(nullable = true)
|-- date: date
(nullable = true)

```

3. Написать аггрегаты продаж товаров по категориям и сохранить результат в формате parquet.

```scala
import spark.implicits._

val dfShopShemaAgg = dfShopShema
  .groupBy($"category_code")
  .agg(max($"price").as("max_price"),
    min($"price").as("min_price"),
    round(avg($"price"), 2).as("avg_price"),
    round(sum($"price"), 2).as("sum_of_price")
  )
  .orderBy("category_code")

dfShopShemaAgg.show(20, 100)

// dfShopShema.withColumn("category_code_cls", trim($"category_code")).drop("category_code").show()

dfShopShemaAgg
  .write
  .mode("overwrite")
  .format("parquet")
  .save("/data/shop_category_task_2")
```